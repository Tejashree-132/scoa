{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# --- Step 1: Load stock data from CSV ---\n",
        "full_df = pd.read_csv(\"/content/SCOA_A5.csv\")\n",
        "\n",
        "# Filter for a single stock (e.g., 'AAL')\n",
        "ticker = 'AAL'\n",
        "df = full_df[full_df['Name'] == ticker].copy()\n",
        "\n",
        "if df.empty:\n",
        "    print(f\"Error: Ticker '{ticker}' not found in the CSV file.\")\n",
        "else:\n",
        "    # Ensure data is sorted by date\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df = df.sort_values('date')\n",
        "\n",
        "    # Create the 'Target' column (1 if next day's close is higher, 0 otherwise)\n",
        "    # Note: Using lowercase 'close' to match the CSV\n",
        "    df['Target'] = (df['close'].shift(-1) > df['close']).astype(int)\n",
        "\n",
        "    # Drop the last row as it will have NaN for the Target\n",
        "    df = df.dropna()\n",
        "\n",
        "    # --- Step 2: Feature selection and scaling ---\n",
        "    # Using lowercase column names from the CSV\n",
        "    features_list = ['open', 'high', 'low', 'close', 'volume']\n",
        "    features = df[features_list]\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    X = scaler.fit_transform(features)\n",
        "    y = df['Target'].values\n",
        "\n",
        "    # --- Step 3: Train-test split ---\n",
        "    # shuffle=False is important to keep the time-series order\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "    # --- Step 4: Build ANN model ---\n",
        "    # The input_dim is 5 (for the 5 features we selected)\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_dim=len(features_list), activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Use the same epochs and batch size you had\n",
        "    model.fit(X_train, y_train, epochs=60, batch_size=42, verbose=1)\n",
        "\n",
        "    # --- Step 5: Evaluate model ---\n",
        "    y_pred_proba = model.predict(X_test)\n",
        "    y_pred = (y_pred_proba > 0.5).astype(\"int32\")\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n--- Model Evaluation for {ticker} ---\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "    print(\"---------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4-1Ls_zPRv6",
        "outputId": "cdd2c0b9-2248-4088-9abe-4837e61e940a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5196 - loss: 0.6958\n",
            "Epoch 2/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5281 - loss: 0.6927 \n",
            "Epoch 3/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5479 - loss: 0.6909 \n",
            "Epoch 4/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5379 - loss: 0.6914 \n",
            "Epoch 5/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5226 - loss: 0.6908\n",
            "Epoch 6/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5310 - loss: 0.6910 \n",
            "Epoch 7/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5346 - loss: 0.6899 \n",
            "Epoch 8/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5131 - loss: 0.6909 \n",
            "Epoch 9/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5225 - loss: 0.6897\n",
            "Epoch 10/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5351 - loss: 0.6878 \n",
            "Epoch 11/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5573 - loss: 0.6894 \n",
            "Epoch 12/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5232 - loss: 0.6911 \n",
            "Epoch 13/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5209 - loss: 0.6911 \n",
            "Epoch 14/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5749 - loss: 0.6836 \n",
            "Epoch 15/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5430 - loss: 0.6860 \n",
            "Epoch 16/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5236 - loss: 0.6897\n",
            "Epoch 17/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5560 - loss: 0.6837 \n",
            "Epoch 18/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5254 - loss: 0.6881 \n",
            "Epoch 19/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5361 - loss: 0.6882 \n",
            "Epoch 20/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5631 - loss: 0.6825 \n",
            "Epoch 21/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5274 - loss: 0.6868 \n",
            "Epoch 22/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5242 - loss: 0.6838 \n",
            "Epoch 23/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5414 - loss: 0.6871 \n",
            "Epoch 24/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5227 - loss: 0.6876 \n",
            "Epoch 25/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5703 - loss: 0.6864 \n",
            "Epoch 26/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5276 - loss: 0.6916 \n",
            "Epoch 27/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5266 - loss: 0.6884 \n",
            "Epoch 28/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5302 - loss: 0.6850 \n",
            "Epoch 29/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5641 - loss: 0.6822 \n",
            "Epoch 30/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5537 - loss: 0.6861 \n",
            "Epoch 31/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5442 - loss: 0.6869 \n",
            "Epoch 32/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5415 - loss: 0.6866 \n",
            "Epoch 33/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5451 - loss: 0.6840 \n",
            "Epoch 34/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5423 - loss: 0.6894 \n",
            "Epoch 35/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5545 - loss: 0.6856 \n",
            "Epoch 36/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5202 - loss: 0.6898 \n",
            "Epoch 37/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5394 - loss: 0.6866 \n",
            "Epoch 38/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5465 - loss: 0.6829 \n",
            "Epoch 39/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5637 - loss: 0.6904 \n",
            "Epoch 40/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5493 - loss: 0.6863 \n",
            "Epoch 41/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5291 - loss: 0.6872 \n",
            "Epoch 42/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5387 - loss: 0.6874 \n",
            "Epoch 43/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5679 - loss: 0.6800 \n",
            "Epoch 44/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5560 - loss: 0.6835 \n",
            "Epoch 45/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5524 - loss: 0.6838 \n",
            "Epoch 46/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5201 - loss: 0.6860 \n",
            "Epoch 47/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5150 - loss: 0.6856 \n",
            "Epoch 48/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5480 - loss: 0.6801 \n",
            "Epoch 49/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5217 - loss: 0.6904\n",
            "Epoch 50/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5409 - loss: 0.6830 \n",
            "Epoch 51/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5319 - loss: 0.6866 \n",
            "Epoch 52/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5588 - loss: 0.6799 \n",
            "Epoch 53/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5391 - loss: 0.6828 \n",
            "Epoch 54/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5487 - loss: 0.6836 \n",
            "Epoch 55/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5324 - loss: 0.6834 \n",
            "Epoch 56/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5418 - loss: 0.6850 \n",
            "Epoch 57/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5426 - loss: 0.6835 \n",
            "Epoch 58/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5335 - loss: 0.6861 \n",
            "Epoch 59/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5507 - loss: 0.6834 \n",
            "Epoch 60/60\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5108 - loss: 0.6878\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "\n",
            "--- Model Evaluation for AAL ---\n",
            "Accuracy: 0.55\n",
            "Confusion Matrix:\n",
            "[[83 40]\n",
            " [73 56]]\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Import libraries\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "```\n",
        "\n",
        "* **numpy**: for numerical operations\n",
        "* **pandas**: for handling CSV and DataFrames\n",
        "* **MinMaxScaler**: scales numerical data into [0,1] range\n",
        "* **train_test_split**: splits dataset into training and testing\n",
        "* **accuracy_score, confusion_matrix**: to evaluate the model’s performance\n",
        "* **Sequential, Dense**: build a feed-forward neural network\n",
        "\n",
        "---\n",
        "\n",
        "Step 2: Load the stock data\n",
        "\n",
        "```python\n",
        "full_df = pd.read_csv(\"/content/SCOA_A5.csv\")\n",
        "```\n",
        "\n",
        "Reads your dataset `SCOA_A5.csv` which likely has columns like `Name, date, open, high, low, close, volume`.\n",
        "\n",
        "---\n",
        "\n",
        "Step 3: Filter one stock (AAL)\n",
        "\n",
        "```python\n",
        "ticker = 'AAL'\n",
        "df = full_df[full_df['Name'] == ticker].copy()\n",
        "```\n",
        "\n",
        "Here we only keep rows for **American Airlines (AAL)**.\n",
        "If this company name doesn’t exist, it prints an error.\n",
        "\n",
        "---\n",
        "\n",
        "Step 4: Sort by date\n",
        "\n",
        "```python\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df.sort_values('date')\n",
        "```\n",
        "\n",
        "Ensures that the data is **chronologically ordered**, which is essential for time-series tasks like stock prediction.\n",
        "\n",
        "---\n",
        "Step 5: Create the Target variable\n",
        "\n",
        "```python\n",
        "df['Target'] = (df['close'].shift(-1) > df['close']).astype(int)\n",
        "```\n",
        "\n",
        "Here’s what it does:\n",
        "\n",
        "* `df['close'].shift(-1)` → next day’s close price\n",
        "* Compares with current day’s close\n",
        "* If **next day’s price is higher**, `Target = 1` (buy signal)\n",
        "* If **lower**, `Target = 0` (sell/hold signal)\n",
        "\n",
        "Then:\n",
        "\n",
        "```python\n",
        "df = df.dropna()\n",
        "```\n",
        "\n",
        "Drops the last row (since it has no next-day price).\n",
        "\n",
        "---\n",
        "\n",
        "Step 6: Feature selection and normalization\n",
        "\n",
        "```python\n",
        "features_list = ['open', 'high', 'low', 'close', 'volume']\n",
        "features = df[features_list]\n",
        "```\n",
        "\n",
        "Selecting the key 5 numeric features.\n",
        "\n",
        "```python\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(features)\n",
        "```\n",
        "\n",
        "All feature values are normalized between 0 and 1 to help the neural network train efficiently.\n",
        "\n",
        "```python\n",
        "y = df['Target'].values\n",
        "```\n",
        "\n",
        "Target (0 or 1) is extracted as output labels.\n",
        "\n",
        "---\n",
        "\n",
        "Step 7: Split into training and testing sets\n",
        "\n",
        "```python\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, shuffle=False)\n",
        "```\n",
        "\n",
        "* 80% data → training\n",
        "* 20% data → testing\n",
        "* `shuffle=False` ensures time-order is preserved (since stock data is sequential).\n",
        "\n",
        "---\n",
        "\n",
        "Step 8: Build the ANN model\n",
        "\n",
        "```python\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=len(features_list), activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "```\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "| Layer | Type  | Units | Activation | Purpose                                    |\n",
        "| ----- | ----- | ----- | ---------- | ------------------------------------------ |\n",
        "| 1     | Dense | 64    | ReLU       | Extract nonlinear patterns                 |\n",
        "| 2     | Dense | 32    | ReLU       | Deeper feature learning                    |\n",
        "| 3     | Dense | 1     | Sigmoid    | Output between 0 and 1 (binary prediction) |\n",
        "\n",
        "---\n",
        "\n",
        "Step 9: Compile model\n",
        "\n",
        "```python\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "* **Loss**: Binary Crossentropy (since output is 0/1)\n",
        "* **Optimizer**: Adam (adaptive learning rate)\n",
        "* **Metrics**: Accuracy\n",
        "\n",
        "---\n",
        "\n",
        "Step 10: Train the model\n",
        "\n",
        "```python\n",
        "model.fit(X_train, y_train, epochs=60, batch_size=42, verbose=1)\n",
        "```\n",
        "\n",
        "* Trains for **60 epochs** (passes through the dataset 60 times)\n",
        "* Batch size 42 (samples processed before updating weights)\n",
        "* Shows progress per epoch\n",
        "\n",
        "---\n",
        "\n",
        "tep 11: Evaluate model\n",
        "\n",
        "```python\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = (y_pred_proba > 0.5).astype(\"int32\")\n",
        "```\n",
        "\n",
        "* Predicts probabilities\n",
        "* Converts them to class labels (0 or 1)\n",
        "\n",
        "---\n",
        "\n",
        "Step 12: Compute accuracy and confusion matrix\n",
        "\n",
        "```python\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "```\n",
        "\n",
        "* Accuracy = % of correct predictions\n",
        "* Confusion matrix = table of correct vs incorrect predictions\n",
        "\n",
        "---\n",
        "\n",
        "#OUTPUT EXPLANATION\n",
        "\n",
        "Means:\n",
        "\n",
        "* **Epoch 1/60**: First iteration of training\n",
        "* **24/24**: 24 batches processed (since total samples ÷ batch_size ≈ 24)\n",
        "* **Loss = 0.6958**: Error (want it to go ↓)\n",
        "* **Accuracy = 0.5196**: ~52% accuracy during training\n",
        "\n",
        "You can observe:\n",
        "\n",
        "* Loss **decreases slightly** (from 0.695 → ~0.68)\n",
        "* Accuracy **fluctuates between 50–57%**\n",
        "\n",
        "This means the network is learning *slightly* but is struggling to generalize — which is common with **stock data** (very noisy).\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "```\n",
        "--- Model Evaluation for AAL ---\n",
        "Accuracy: 0.55\n",
        "Confusion Matrix:\n",
        "[[83 40]\n",
        " [73 56]]\n",
        "---------------------------------\n",
        "```\n",
        "\n",
        "Let’s decode this:\n",
        "```\n",
        "| Metric               | Meaning                                                                                                           |\n",
        "| -------------------- | ----------------------------------------------------------------------------------------------------------------- |\n",
        "| **Accuracy: 0.55**   | The model predicts the next-day direction correctly 55% of the time — slightly better than random guessing (50%). |\n",
        "| **Confusion Matrix** |                                                                                                                   |\n",
        "```\n",
        "```\n",
        "[[83 40]\n",
        " [73 56]]\n",
        "```\n",
        "\n",
        "| True class     | Predicted as 0 | Predicted as 1 |\n",
        "| -------------- | -------------- | -------------- |\n",
        "| 0 (price down) | 83             | 40             |\n",
        "| 1 (price up)   | 73             | 56             |\n",
        "\n",
        "So:\n",
        "\n",
        "* 83 → Correctly predicted price went down\n",
        "* 56 → Correctly predicted price went up\n",
        "* 40 + 73 = 113 → total wrong predictions\n",
        "\n",
        "---\n",
        "\n",
        "INTERPRETATION\n",
        "\n",
        "*Good signs:*\n",
        "\n",
        "* Model is able to learn some trend signals.\n",
        "* Accuracy > 50% means it’s learning *some* pattern beyond random.\n",
        "\n",
        "**Issues / Improvements:**\n",
        "\n",
        "1. Add more features: moving averages, RSI, MACD, etc.\n",
        "2. Use time-series models (LSTM, GRU) — better for sequence data.\n",
        "3. Try longer training (more epochs, smaller learning rate).\n",
        "4. Feature engineering and normalization consistency are key.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QgqX91k1YZXw"
      }
    }
  ]
}